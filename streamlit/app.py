import streamlit as st
from streamlit_drawable_canvas import st_canvas
import cv2
import numpy as np
import tempfile
import os
from PIL import Image
from io import BytesIO

from video_analyzer_yolo import convert_to_h264, analyze_video_with_tracking  # YOLO + counting ë¶„ì„ í•¨ìˆ˜

st.set_page_config(page_title="YOLO Line-Counter", layout="centered") # 740px
# st.set_page_config(page_title="YOLO Line-Counter", layout="wide")
st.title("ğŸ” YOLO + Line Crossing Counting")
st.markdown("""
        <style>
        body {
            background-color: #e6e6fa; /* ì—°ë³´ë¼ìƒ‰ */
        }

        [data-testid="stAppViewContainer"] {
            background-color: #e6e6fa; /* ì „ì²´ í˜ì´ì§€ ë°°ê²½ */
        }

        [data-testid="stHeader"] {
            background-color: #e6e6fa;
        }

        [data-testid="stSidebar"] {
            background-color: #d8bfd8; /* ì‚¬ì´ë“œë°” ë°°ê²½ */
        }

        .stMarkdown, .stText, .stSlider {
            color: #000000; /* ê¸€ì ìƒ‰ */
            font-size: 18px;
        }
        </style>
    """, unsafe_allow_html=True)


st.subheader("ğŸ¥ ë¶„ì„ ì˜ìƒ ì—…ë¡œë“œ")
video_file = st.file_uploader("ì˜ìƒì„ ì—…ë¡œë“œí•˜ì„¸ìš”:)", type=["mp4", "avi", "mov"])

line_coords = []
start_sec, end_sec = 0.0, 0.0
fps = 30

if video_file:
    tfile = tempfile.NamedTemporaryFile(delete=False)
    tfile.write(video_file.read())
    video_path = tfile.name

    cap = cv2.VideoCapture(video_path)
    success, frame = cap.read()
    fps = cap.get(cv2.CAP_PROP_FPS)
    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    duration = frame_count / fps
    cap.release()

    st.markdown("---")
    st.subheader("ğŸ–Šï¸ Line ì„¤ì •")

    if success:
        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        frame_pil = Image.fromarray(frame_rgb)
        canvas_width, canvas_height = frame_pil.size

        # ì›í•˜ëŠ” ìº”ë²„ìŠ¤ ë„ˆë¹„ (ì˜ˆ: 740px)
        target_width = 700
        orig_width, orig_height = frame_pil.size
        scale_ratio = target_width / orig_width
        canvas_width = target_width
        canvas_height = int(orig_height * scale_ratio)

        # st.image(frame_rgb, caption="ğŸ¯ ì²« í”„ë ˆì„", use_column_width=True)

        canvas_result = st_canvas(
            fill_color="rgba(255, 0, 0, 0.3)",
            stroke_width=3,
            stroke_color="#00f",
            background_image=frame_pil.resize((canvas_width, canvas_height)),
            update_streamlit=True,
            height=canvas_height,
            width=canvas_width,
            drawing_mode="line",
            key="canvas"
        )

        # ì¢Œí‘œ ë³µì› (scale up to original resolution)
        if canvas_result.json_data and canvas_result.json_data["objects"]:
            for obj in canvas_result.json_data["objects"]:
                if obj["type"] == "line":
                    left = obj["left"]
                    top = obj["top"]
                    x1 = (left + obj["x1"]) / scale_ratio
                    y1 = (top + obj["y1"]) / scale_ratio
                    x2 = (left + obj["x2"]) / scale_ratio
                    y2 = (top + obj["y2"]) / scale_ratio
                    line_coords.append(((x1, y1), (x2, y2)))

            st.success(f"âœ… ì´ {len(line_coords)}ê°œì˜ ì„ ì´ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤.")
        else:
            st.info("ì„ ì„ ê·¸ë ¤ì£¼ì„¸ìš”!")

        st.markdown("---")

        # st.video(video_path)  # ì´ê²Œ ìŠ¬ë¼ì´ë”ë³´ë‹¤ ìœ„ì— ìˆì–´ì•¼ í•¨
        print(f"line_coords : {line_coords}")

        st.subheader("â±ï¸ ë¶„ì„ êµ¬ê°„ ì„ íƒ")
        start_sec, end_sec = st.slider(
            "ë¶„ì„í•  ì˜ìƒ êµ¬ê°„ (ì´ˆ ë‹¨ìœ„)",
            min_value=0.0,
            max_value=round(duration, 2),
            value=(0.0, round(duration, 2)),
            step=0.1
        )

        st.markdown("---")

        # ëª¨ë¸ í´ë˜ìŠ¤ ì´ë¦„ ë¯¸ë¦¬ ì •ì˜ ë˜ëŠ” model ë¶ˆëŸ¬ì™€ì„œ ê°€ì ¸ì˜¤ê¸°
        # ì˜ˆì‹œ: COCO í´ë˜ìŠ¤
        coco_class_names = [
            "pear_bag", "person", "bicycle", "car", "motorcycle", "airplane", "bus", "train", "truck", "boat",
            "traffic light", "fire hydrant", "stop sign", "parking meter", "bench", "bird", "cat",
            "dog", "horse", "sheep", "cow", "elephant", "bear", "zebra", "giraffe", "backpack",
            "umbrella", "handbag", "tie", "suitcase", "frisbee", "skis", "snowboard", "sports ball",
            "kite", "baseball bat", "baseball glove", "skateboard", "surfboard", "tennis racket",
            "bottle", "wine glass", "cup", "fork", "knife", "spoon", "bowl", "banana", "apple",
            "sandwich", "orange", "broccoli", "carrot", "hot dog", "pizza", "donut", "cake", "chair",
            "couch", "potted plant", "bed", "dining table", "toilet", "tv", "laptop", "mouse", "remote",
            "keyboard", "cell phone", "microwave", "oven", "toaster", "sink", "refrigerator", "book",
            "clock", "vase", "scissors", "teddy bear", "hair drier", "toothbrush"
        ]
        
        # ğŸ¯ ì‚¬ìš©ì í´ë˜ìŠ¤ ì„ íƒ
        st.subheader("ğŸ‘€ ì¶”ì í•  ê°ì²´ í´ë˜ìŠ¤ ì„ íƒ")
        selected_class_names = st.multiselect("í´ë˜ìŠ¤ë¥¼ í•˜ë‚˜ ì´ìƒ ì„ íƒí•˜ì„¸ìš”", coco_class_names, default=["person"])
        wanted_class_ids = [i for i, name in enumerate(coco_class_names) if name in selected_class_names]

        st.markdown("---")
        st.subheader("ğŸ¤– AI ë¶„ì„")
        
if video_file and line_coords and st.button("ğŸ“Š ë¶„ì„ ì‹œì‘"):
    with st.spinner("YOLO ë¶„ì„ ì¤‘..."):
        result = analyze_video_with_tracking(
            # video_path, line_coords, start_sec, end_sec, fps, wanted_class_ids
            video_path, line_coords, start_sec, end_sec, fps, selected_class_names
        )

        print(f"result 1 : {result}")
        st.session_state["analyzed"] = True
        st.session_state["result"] = result

if st.session_state.get("analyzed"):
    result = st.session_state["result"]

    st.markdown("---")

    import io

    st.markdown("### âœ… ë¶„ì„ ê²°ê³¼ ìš”ì•½")

    col1, col2 = st.columns(2)
    with col1:
        st.metric("ğŸ” ì¶”ì ëœ ê°ì²´ ìˆ˜", f"{result['total_tracked_objects']}ê°œ")
    with col2:
        st.metric("ğŸš¦ Line ê±´ë„Œ íšŸìˆ˜", f"{result['line_cross_count']}íšŒ")

    st.markdown("---")
    st.video(result['output_video_path'])

    # âœ… ë¶„ì„ ê²°ê³¼ í…ìŠ¤íŠ¸ ìƒì„± (ë¬¸ìì—´ â†’ ë°”ì´íŠ¸)
    summary_text = f"""ğŸ“„ ë¶„ì„ ê²°ê³¼ ìš”ì•½
    --------------------------
    ğŸ” ì´ ì¶”ì ëœ ê°ì²´ ìˆ˜: {result['total_tracked_objects']}ê°œ
    ğŸš¦ ì´ Line ê±´ë„Œ íšŸìˆ˜: {result['line_cross_count']}íšŒ
    """
    summary_bytes = summary_text.encode('utf-8')  # âš ï¸ ì—¬ê¸° ì¤‘ìš”

    # âœ… í…ìŠ¤íŠ¸ íŒŒì¼ ë‹¤ìš´ë¡œë“œ
    st.download_button(
        label="ğŸ“„ ë¶„ì„ ê²°ê³¼ í…ìŠ¤íŠ¸ ë‹¤ìš´ë¡œë“œ",
        data=summary_bytes,
        file_name="analysis_summary.txt",
        mime="text/plain"
    )

    # ğŸï¸ ê²°ê³¼ ì˜ìƒ ë‹¤ìš´ë¡œë“œ
    with open(result['output_video_path'], "rb") as f:
        video_bytes = f.read()

    st.download_button(
        label="ğŸ“¥ ê²°ê³¼ ì˜ìƒ ë‹¤ìš´ë¡œë“œ",
        data=video_bytes,
        file_name="result_video.mp4",
        mime="video/mp4"
    )
